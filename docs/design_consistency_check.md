# 政务热线工单质量智能检测系统设计 (V1.3 完整版)

## 1. 项目定义与核心价值
**项目定义**：基于语音理解与语义对齐的热线工单质量智能检测系统。
**核心价值**：自动比对群众“真实诉求”与话务员“交办工单”内容，对“是否听懂、是否记准、是否交清、是否规范”进行量化评分与问题定位。

## 2. 核心问题：诉求语义一致性检测
本项目不关注“分类分转”（已有模块负责），而是聚焦于 **话务员的记录质量**：
*   **群众真正说了什么？** (Transcript / Dialogue Summary)
*   **工单最终写成了什么？** (Work Order)
*   **中间偏差在哪里？** (Consistency Gap)

## 3. 评价指标体系 (V1.1 成熟版)
我们采用不涉及部门分转的“纯净版”质量指标，更符合质检定位：

| 维度 | 分值 | 核心考察点 | 典型问题 |
| :--- | :--- | :--- | :--- |
| **诉求完整性 (Completeness)** | 35分 | 是否遗漏关键事实 / 多项诉求 | 漏记时间地点、漏记次要诉求 |
| **语义一致性 (Consistency)** | 30分 | 工单是否准确反映群众真实诉求 | 投诉变咨询、情绪降级、事实偏差 |
| **表述规范性 (Clarity)** | 20分 | 语言是否规范、清晰、无歧义 | 模糊词、指代不清、语病 |
| **风险敏感性 (Risk Awareness)** | 15分 | 是否识别潜在升级、舆情风险 | 忽略激进情绪、弱化重复投诉风险 |

## 4. 核心技术架构 (V1.0 -> V1.3 演进)

### V1.0: 基础评分
*   基于 LLM 进行四维度评分。
*   输出：分数、扣分点、改进建议。

### V1.1: 置信度与人工复核
*   引入 **Confidence (0.0-1.0)**：系统对自己判断的自信程度。
*   引入 **Need Human Review (Boolean)**：明确建议是否需要人工介入。
*   **价值**：将人工从海量阅卷中解放，仅关注低置信度/高风险单。

### V1.2: 置信度分桶策略
*   **高置信度 (≥0.85)**：自动采信，用于统计分析。
*   **中置信度 (0.70-0.84)**：抽检复核，用于优化规则。
*   **低置信度 (<0.70)**：强制人工复核，用于兜底风险。

### V1.3: 动态校准 (Long-term Calibration)
置信度不再是单次判断，而是结合历史数据的 **综合可信度 (Adjusted Confidence)**：
1.  **历史一致性**：该话务员/场景的历史机评与人评一致率。
2.  **投诉回访结果**：事后群众满意度反向校准风险判断。
3.  **领导复核偏差**：权威判断校准系统边界。

## 5. 系统输入输出结构

### 输入
```json
{
  "dialogue_summary": "群众真实诉求的结构化摘要",
  "work_order": {
    "title": "工单标题",
    "content": "工单正文",
    "priority": "优先级"
  },
  "history_factors": {
    "agent_consistency_score": 0.92,
    "has_callback_complaint": false
  }
}
```

### 输出 (标准 JSON)
```json
{
  "scores": {
    "completeness": { "score": 28, "judgement": "基本完整", "issues": [...] },
    "consistency": { "score": 24, "judgement": "部分偏差", "issues": [...] },
    "clarity": { "score": 18, "judgement": "规范", "issues": [...] },
    "risk_awareness": { "score": 10, "judgement": "一般", "issues": [...] }
  },
  "total_score": 80,
  "overall_level": "合格",
  "confidence": 0.85,
  "adjusted_confidence": 0.88,
  "need_human_review": false,
  "suggestion": "..."
}
```
